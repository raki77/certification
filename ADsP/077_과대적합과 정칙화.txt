	1. 과대적합과 과소적합
	2. 과대적합 문제와 해결 방법
	3. 정칙화 (정규화 + 규제,  Regularization) 개념
	
	4. L1, L2 norm
		a. Norm : 선형대수학에서 벡터 크기 또는 길이를 측정하는 방법이다.
	
	5. 정규화 선형회귀 모델
	
		a. 라쏘(Lasso) 회귀
			i. L1 norm
			ii. 회귀계수 [절대값] 이 클수록, 더 큰 패널티 부여
			iii. 회귀계수 절대값의 합에 람다(lamda)를 곱한 것이다.
	
		b. 릿지(Ridge)회귀 (= 능형회귀)
			i. L2 norm
			ii. 회귀계수 [제곱값]이 클수록, 더 큰 패널티 부여
			iii. 변수 선택이 불가능하다.
			iv. Lasso 는 가중치들이 0이 된다. 하지만
			v. Ridge 가중치는 0이 되지 않는다. (그냥 가까워 질 뿐이다.)
			vi. 제곱값의 합에 람다(lamda)를 곱한 것이다.
	
		c. 엘라스틱넷 회귀
			i. L1, L2 모두 사용
			ii. 변수 선택가능, 변수 간 상관관계 반영 가능한 Regularization 된다.
	
	
	6. 편향과 분산 (Bias and Variance)
		a. 학습 알고리즘이 가지는 2가지 종류 오류(Error)이다. 
		b. 상충관계이다. (Trade off)
		c. 학습 모형이 [유연] 할수록???
			i. 모델 복잡도 증가한다.
			ii. [편향]이 [낮다]
        [분산]은 [높은 상태]가 된다.